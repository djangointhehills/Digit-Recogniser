{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook is purely for my own learning.\n\n**Aims:**\n\n- Implement a CNN using the Kaggle ['Digit Recogniser'](https://www.kaggle.com/c/digit-recognizer/overview) competition dataset. \n- Use TPU.\n- Explore data augmentation.\n\n\n**Outcomes so far:**\n\nSuccessful implentation of CNN using TPU. \n\nUnable to augment data in model as suggested by the TensorFlow [documentation](https://www.tensorflow.org/tutorials/images/data_augmentation). I want to have the benefits of saving the augmentations as these seem to me to be an integral part of the model.\n\nI have however managed to successfully augment the data (not in this notebook) without the use of the TPU, which coincidentally had the best results.\n\nOne consideration is that the model test/train accuracy is optimal at around 4 epochs. This suggests that the TPU might be overkill and the model might be better using the CPU and having data augmentation.\n\n**Future Endeavours:**\n\n- Get data augmentation and TPU working optimally.\n- Save best model in training.\n\n**Resourses:**\n\n[One.](https://www.kaggle.com/bryanb/keras-cnn-for-mnist-digit-recognition-with-tpus#1.-Load-libraries-and-check-TPU-settings)\n[Two.](https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu)\n[Three.](https://www.tensorflow.org/tutorials/load_data/images)","metadata":{"_uuid":"b6409eaa-5bf8-4215-8ac1-c9d555168327","_cell_guid":"9ae082a8-e863-44af-a152-0f4dc442e95a"}},{"cell_type":"markdown","source":"# Imports","metadata":{"_uuid":"64744c85-1e26-4175-9e3f-c446fc2f758c","_cell_guid":"43d3c480-c73d-4a2b-84ee-31c6c995099b","trusted":true}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nimport math\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nfrom numpy.random import randint\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport time, os\nimport torch\nfrom torch.utils import data\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"_uuid":"e3e71ffb-1e94-45dc-8c1f-08126ce23a58","_cell_guid":"0f3678d0-1f35-4c0f-8dc0-390ded097b85","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:11:26.428246Z","iopub.execute_input":"2021-08-06T07:11:26.428709Z","iopub.status.idle":"2021-08-06T07:11:26.445562Z","shell.execute_reply.started":"2021-08-06T07:11:26.428673Z","shell.execute_reply":"2021-08-06T07:11:26.444404Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU","metadata":{"_uuid":"3d8a435d-2553-4566-9ef7-5dd94b0ecafb","_cell_guid":"f5fce711-e950-4d62-b5a6-e1d18aa6fa4d","trusted":true}},{"cell_type":"code","source":"# Detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# Instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"_uuid":"ec73719b-b97c-4366-b51e-0b250368cc7b","_cell_guid":"7178bb5c-1b3a-429c-86a4-26de64ab9b6d","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:11:26.447042Z","iopub.execute_input":"2021-08-06T07:11:26.447355Z","iopub.status.idle":"2021-08-06T07:11:31.695417Z","shell.execute_reply.started":"2021-08-06T07:11:26.447321Z","shell.execute_reply":"2021-08-06T07:11:31.694345Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Variables","metadata":{"_uuid":"7580848d-6fb1-4f3a-bf5c-bf45afecd909","_cell_guid":"895c0e79-a2e9-4cf1-a7b1-c5b42de972f6","trusted":true}},{"cell_type":"code","source":"BATCH_SIZE = 32 * tpu_strategy.num_replicas_in_sync # this is 8 on TPU v3-8, it is 1 on CPU and GPU\nIMAGE_SIZE = [28, 28]\nHEIGHT = 28\nWIDTH = 28\nCHANNELS = 1\nEPOCHS = 30","metadata":{"_uuid":"1c9c2861-1260-46a1-be2a-30ee85e0ebab","_cell_guid":"cce8d3c3-28aa-4384-82ea-6caa593dfe94","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:11:31.697155Z","iopub.execute_input":"2021-08-06T07:11:31.697470Z","iopub.status.idle":"2021-08-06T07:11:31.702337Z","shell.execute_reply.started":"2021-08-06T07:11:31.697438Z","shell.execute_reply":"2021-08-06T07:11:31.701284Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data in","metadata":{"_uuid":"f98afede-469f-43c1-83d6-a6dfba2eb2b4","_cell_guid":"692518e4-f7b0-47d4-88f1-8b1759d5aa10","trusted":true}},{"cell_type":"code","source":"# Load in data.\ntrain_data = pd.read_csv('../input/digit-recognizer/train.csv')\ntest_data = pd.read_csv('../input/digit-recognizer/test.csv')","metadata":{"_uuid":"b2ad6657-acba-461c-b28d-e793c3280f47","_cell_guid":"9fe5956c-d70d-4709-940f-b22e8ac8fd71","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:11:31.704317Z","iopub.execute_input":"2021-08-06T07:11:31.704745Z","iopub.status.idle":"2021-08-06T07:11:36.447144Z","shell.execute_reply.started":"2021-08-06T07:11:31.704701Z","shell.execute_reply":"2021-08-06T07:11:36.446032Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split and reshape data.\ntrain_y = train_data.label.to_numpy()\ntrain_x = train_data.to_numpy()[0:,1:].reshape(len(train_data),28,28,1)\ntest_x = test_data.to_numpy().reshape(len(test_data),28,28,1)\n\n# Normalise - to speed up model. Better if values are between [0,1] then [0,255].\ntrain_x = train_x/255\ntest_x = test_x/255\n\ntrain_x, dev_x, train_y, dev_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)","metadata":{"_uuid":"38cdf795-6839-43e8-88eb-04434787db47","_cell_guid":"be64c6c3-cbe2-4f2e-a37c-fbccc03bcc05","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:11:36.449115Z","iopub.execute_input":"2021-08-06T07:11:36.449548Z","iopub.status.idle":"2021-08-06T07:11:37.018192Z","shell.execute_reply.started":"2021-08-06T07:11:36.449501Z","shell.execute_reply":"2021-08-06T07:11:37.017272Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploration","metadata":{"_uuid":"8c1a56d4-7c7d-4aee-bf72-7eca229824f9","_cell_guid":"6601223a-2d62-4eb1-a174-838130eccd50","trusted":true}},{"cell_type":"markdown","source":"The competition description reads as follows:\n\n\"MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n\nIn this competition, your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.\"","metadata":{"_uuid":"ceb2a4b1-9d94-4172-910a-a23af84eb8df","_cell_guid":"307a53c6-a11a-496d-a510-967603ded740","trusted":true}},{"cell_type":"code","source":"# Check one image and its actual label\nindex = randint(0, len(train_x))\nimage = train_x[index]\nplt.imshow(image.squeeze())\nprint('Label =', train_y[index])","metadata":{"_uuid":"c886ded2-5214-4e17-a85d-877c40cdbfe9","_cell_guid":"a92a5718-113d-4bb6-afe3-d3632210fdfe","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:50:11.133135Z","iopub.execute_input":"2021-08-06T07:50:11.133546Z","iopub.status.idle":"2021-08-06T07:50:11.306368Z","shell.execute_reply.started":"2021-08-06T07:50:11.133497Z","shell.execute_reply":"2021-08-06T07:50:11.305460Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check labels and the distribution of them.\nx, y = np.unique(train_y, return_counts=True)\nplt.figure(figsize = (10,7))\nplt.title('Class Distribution')\nplt.bar(x,y)\nplt.ylabel('Number')\nplt.xlabel('Counts')\nplt.xticks(np.arange(0, 10, step=1))\nplt.show()","metadata":{"_uuid":"391ab7b6-8788-4933-bad9-b99be4d48657","_cell_guid":"97f2afeb-9849-48a3-9981-e6086e4536f8","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:11:37.198842Z","iopub.execute_input":"2021-08-06T07:11:37.199185Z","iopub.status.idle":"2021-08-06T07:11:37.398322Z","shell.execute_reply.started":"2021-08-06T07:11:37.199151Z","shell.execute_reply":"2021-08-06T07:11:37.397091Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Tensorflow dataset","metadata":{"_uuid":"bc7f9769-f1bd-4cea-bf94-e57a93d4bb53","_cell_guid":"c91f1dd7-e7ff-46e5-b5bb-71e37ee96222","trusted":true}},{"cell_type":"code","source":"# Put data in a tensor format for parallelization\n\ntrain_dataset = (\n    tf.data.Dataset.from_tensor_slices((train_x.astype(np.float32), train_y.astype(np.float32)))\n    .repeat()\n    .shuffle(2048)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\ndev_dataset = (\n    tf.data.Dataset.from_tensor_slices((dev_x.astype(np.float32), dev_y.astype(np.float32)))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset.from_tensor_slices(test_x.astype(np.float32)).batch(BATCH_SIZE)\n)","metadata":{"_uuid":"905dbbbf-2131-4a6e-8cbc-01d00137d0e3","_cell_guid":"831bfe99-312e-480e-b24f-31a707e48109","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:11:37.401290Z","iopub.execute_input":"2021-08-06T07:11:37.401711Z","iopub.status.idle":"2021-08-06T07:11:38.399271Z","shell.execute_reply.started":"2021-08-06T07:11:37.401672Z","shell.execute_reply":"2021-08-06T07:11:38.398135Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"_uuid":"f9537aae-c957-4ee3-a2d3-0492176efdcc","_cell_guid":"7c738b6b-194a-4296-9c33-9eab3d215b20","trusted":true}},{"cell_type":"code","source":"# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model = keras.Sequential([\n                layers.InputLayer(input_shape=[28,28,1]),\n                \n                # Preprocessing - Augmentation\n                preprocessing.RandomContrast(factor=0.10),\n\n# #                 preprocessing.RandomWidth(factor=0.15), # horizontal stretch\n#                 preprocessing.RandomRotation(factor=0.20),\n# #                 preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n#                 layers.experimental.preprocessing.Rescaling(1./255),\n        \n                # First Convolutional Block\n                layers.BatchNormalization(renorm=True),\n                layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n                layers.MaxPool2D(2),\n\n                # Second Convolutional Block\n                layers.BatchNormalization(renorm=True),\n                layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n                layers.MaxPool2D(2),\n\n                # Third Convolutional Block\n                layers.BatchNormalization(renorm=True),\n                layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding='same'),\n                layers.MaxPool2D(2),\n\n                # Fourth Convolutional Block\n                layers.BatchNormalization(renorm=True),\n                layers.Conv2D(filters=512, kernel_size=3, activation=\"relu\", padding='same'),\n                layers.MaxPool2D(2),\n\n                layers.Flatten(),\n                layers.Dropout(.2),\n\n                layers.Dense(64,activation='relu'),\n                layers.Dense(10,activation='sigmoid')])\n    \n    model.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy'],\n    steps_per_execution=32)","metadata":{"_uuid":"99bd1508-5044-4c94-9a93-991cb519b4b1","_cell_guid":"b7c55775-7591-4857-a032-dd56d96e5e63","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:15:10.414866Z","iopub.execute_input":"2021-08-06T07:15:10.415237Z","iopub.status.idle":"2021-08-06T07:15:11.205174Z","shell.execute_reply.started":"2021-08-06T07:15:10.415205Z","shell.execute_reply":"2021-08-06T07:15:11.204143Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"_uuid":"d3b29cbf-de06-4322-b2c4-96a5a3ddf0a8","_cell_guid":"ea3a2d33-8e7d-41d6-a755-ccc7f28114a4","trusted":true}},{"cell_type":"code","source":"history = model.fit(\n    train_dataset,\n    validation_data=dev_dataset,\n    batch_size = BATCH_SIZE,\n    steps_per_epoch = train_x.shape[0]//BATCH_SIZE,\n    epochs=4,\n    verbose=1,\n)","metadata":{"_uuid":"ee59e492-3363-4d10-ab76-6c39fe27d416","_cell_guid":"cf604200-cb1b-4a72-8e70-302b28d36119","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:15:12.429184Z","iopub.execute_input":"2021-08-06T07:15:12.429547Z","iopub.status.idle":"2021-08-06T07:15:32.555284Z","shell.execute_reply.started":"2021-08-06T07:15:12.429516Z","shell.execute_reply":"2021-08-06T07:15:32.554228Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(model_history):\n\n    plt.figure(figsize = (20,15))\n    \n    plt.subplot(221)\n    # summarize history for accuracy\n    plt.plot(model_history.history['accuracy'])\n    plt.plot(model_history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.grid()\n    \n    plt.subplot(222)\n    # summarize history for loss\n    plt.plot(model_history.history['loss'])\n    plt.plot(model_history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.grid()\n    \n    plt.show()","metadata":{"_uuid":"9cdd8d4b-6d5d-4d2e-aaf6-da5df22cdc3a","_cell_guid":"b0c15da1-0224-43d4-8904-ee0e68d5854f","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:14:40.960171Z","iopub.execute_input":"2021-08-06T07:14:40.960536Z","iopub.status.idle":"2021-08-06T07:14:40.968994Z","shell.execute_reply.started":"2021-08-06T07:14:40.960504Z","shell.execute_reply":"2021-08-06T07:14:40.967886Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"_uuid":"2e03a870-c737-466f-b9de-9c7bf225a234","_cell_guid":"5a61b64e-75bd-4090-9ca8-ac9bb986bd64","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:15:32.556847Z","iopub.execute_input":"2021-08-06T07:15:32.557191Z","iopub.status.idle":"2021-08-06T07:15:32.945342Z","shell.execute_reply.started":"2021-08-06T07:15:32.557160Z","shell.execute_reply":"2021-08-06T07:15:32.944415Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is clear that the model is reasonably well fit as the test and train accuracy and loss have both converged.","metadata":{"_uuid":"7327b62c-3660-4286-8b3d-a279be58682c","_cell_guid":"1c09940a-4f00-4daf-9c5b-3b5bb44e0b8b","trusted":true}},{"cell_type":"code","source":"dev_preds = model.predict(dev_dataset)\ndev_preds = np.argmax(dev_preds, axis=1)","metadata":{"_uuid":"c6326369-4480-40a4-b991-83bb22c83c85","_cell_guid":"6f9ff9a9-6d3f-4079-a090-d2178f49da8f","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:15:51.546132Z","iopub.execute_input":"2021-08-06T07:15:51.546499Z","iopub.status.idle":"2021-08-06T07:15:55.875454Z","shell.execute_reply.started":"2021-08-06T07:15:51.546468Z","shell.execute_reply":"2021-08-06T07:15:55.874396Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot confusion matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfig, ax = plt.subplots(figsize=(12, 12))\ncm = confusion_matrix(dev_y,dev_preds, normalize='true')\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = [0,1,2,3,4,5,6,7,8,9])\ndisp = disp.plot(ax=ax)\nax.set_title(\"Confusion Matrix\")\nplt.show()\n%matplotlib inline","metadata":{"_uuid":"e91fcf80-cd4f-4357-a441-6de8c733894b","_cell_guid":"e4208c74-d5f3-40f2-b1d9-d2f301cd19f3","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:15:55.876939Z","iopub.execute_input":"2021-08-06T07:15:55.877235Z","iopub.status.idle":"2021-08-06T07:15:56.598929Z","shell.execute_reply.started":"2021-08-06T07:15:55.877207Z","shell.execute_reply":"2021-08-06T07:15:56.596643Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While not completely accurate, the results with no data augmentation seems reasonable.","metadata":{"_uuid":"6c4e8723-c55e-436b-b268-2628aef7e73e","_cell_guid":"c3f67398-6bc1-4d7f-a3fa-b15796c24b29","trusted":true}},{"cell_type":"markdown","source":"# Submission Predictions","metadata":{"_uuid":"ad0ba7ee-b04e-4d55-b21f-9c9a163b0d11","_cell_guid":"8976d60a-0089-4b23-b723-b6136554d851","trusted":true}},{"cell_type":"code","source":"# test_data_new = test_data.to_numpy().reshape(len(test_data),28*28)\ntest_preds = model.predict(test_x)\ntest_preds = np.argmax(test_preds, axis=1)\noutput = pd.DataFrame({'ImageId': range(1,28001), 'Label': test_preds})\noutput.to_csv('First.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"_uuid":"b87cc0d6-e466-4086-b0ce-6c86d73d491f","_cell_guid":"64457b92-b17c-4cda-be72-b365af4f7dfa","collapsed":false,"execution":{"iopub.status.busy":"2021-08-06T07:16:00.554332Z","iopub.execute_input":"2021-08-06T07:16:00.554729Z","iopub.status.idle":"2021-08-06T07:16:04.523986Z","shell.execute_reply.started":"2021-08-06T07:16:00.554697Z","shell.execute_reply":"2021-08-06T07:16:04.523187Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}